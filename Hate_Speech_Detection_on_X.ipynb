{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a13899e-c781-4e24-a2e8-04f98d282961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba1e887-4ed3-4b31-8b95-0fb442fba061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded\n",
      "NLTK stopwords loaded\n",
      "NLTK lemmatizer loaded\n"
     ]
    }
   ],
   "source": [
    "# Try to import NLTK components, but provide fallbacks if not available\n",
    "try:\n",
    "    import nltk\n",
    "    # Download NLTK resources with error handling\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    print(\"NLTK resources downloaded\")\n",
    "    \n",
    "    # Check if stopwords are available\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords_available = True\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    print(\"NLTK stopwords loaded\")\n",
    "    \n",
    "    # Check if lemmatizer is available\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer_available = True\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    print(\"NLTK lemmatizer loaded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"NLTK loading error: {e}\")\n",
    "    stopwords_available = False\n",
    "    lemmatizer_available = False\n",
    "    \n",
    "    # Define basic stopwords if NLTK's aren't available\n",
    "    STOPWORDS = {'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'what', 'when', \n",
    "              'where', 'how', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', \n",
    "              'has', 'had', 'do', 'does', 'did', 'to', 'from', 'of', 'at', 'by', 'for', \n",
    "              'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "              'after', 'above', 'below', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "              'under', 'again', 'further', 'then', 'once', 'here', 'there', 'all', 'any', \n",
    "              'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', \n",
    "              'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', \n",
    "              'just', 'should', 'now', 'im', 'youre', 'hes', 'shes', 'theyre', 'weve',\n",
    "              'youve', 'theyve', 'ive', 'doesnt', 'dont', 'cant', 'wont', 'isnt', 'arent'}\n",
    "    print(\"Using basic stopwords list instead of NLTK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f407c4d3-84b9-427a-b772-4042b8a4c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Training data shape: (31962, 3)\n",
      "Test data shape: (17197, 2)\n",
      "\n",
      "Missing values in training data:\n",
      "id       0\n",
      "label    0\n",
      "tweet    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "id       0\n",
      "tweet    0\n",
      "dtype: int64\n",
      "\n",
      "Class distribution in training data:\n",
      "label\n",
      "0    92.98542\n",
      "1     7.01458\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "try:\n",
    "    train_data = pd.read_csv(\"C:/Users/ashir/Downloads/train_E6oV3lV.csv\")\n",
    "    test_data = pd.read_csv(\"C:/Users/ashir/Downloads/test_tweets_anuFYb8.csv\")\n",
    "    \n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values in training data:\")\n",
    "    print(train_data.isnull().sum())\n",
    "    print(\"\\nMissing values in test data:\")\n",
    "    print(test_data.isnull().sum())\n",
    "\n",
    "    # Display class distribution in training data\n",
    "    print(\"\\nClass distribution in training data:\")\n",
    "    print(train_data['label'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e6a827-dd53-458f-8380-0c817f6faa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove hashtags (keep the text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7b58d0-a2fa-424a-b038-e738ec6c2c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n"
     ]
    }
   ],
   "source": [
    "# Apply text cleaning to both datasets\n",
    "print(\"Cleaning text...\")\n",
    "train_data['cleaned_tweet'] = train_data['tweet'].apply(clean_text)\n",
    "test_data['cleaned_tweet'] = test_data['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d5be3b-f0bf-4125-976a-bb901aa32e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function with fallbacks\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Simple tokenization by splitting on whitespace\n",
    "    # This avoids relying on NLTK's word_tokenize\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords if available\n",
    "    if stopwords_available:\n",
    "        try:\n",
    "            tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing stopwords: {e}\")\n",
    "    else:\n",
    "        # Use the basic stopwords list defined earlier\n",
    "        tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    \n",
    "    # Apply lemmatization if available\n",
    "    if lemmatizer_available:\n",
    "        try:\n",
    "            tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        except Exception as e:\n",
    "            print(f\"Error lemmatizing: {e}\")\n",
    "    else:\n",
    "        # Simple stemming as fallback\n",
    "        stemmed_tokens = []\n",
    "        for token in tokens:\n",
    "            if len(token) > 3:  # Only stem if word is longer than 3 characters\n",
    "                if token.endswith('ing') and len(token) > 4:\n",
    "                    token = token[:-3]\n",
    "                elif token.endswith('ed') and len(token) > 3:\n",
    "                    token = token[:-2]\n",
    "                elif token.endswith('es') and len(token) > 3:\n",
    "                    token = token[:-2]\n",
    "                elif token.endswith('s') and len(token) > 2:\n",
    "                    token = token[:-1]\n",
    "            stemmed_tokens.append(token)\n",
    "        tokens = stemmed_tokens\n",
    "    \n",
    "    # Rejoin tokens to form preprocessed text\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9cf76bc-d223-494f-b7df-574466d19291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "print(\"Preprocessing text...\")\n",
    "train_data['processed_tweet'] = train_data['cleaned_tweet'].apply(preprocess_text)\n",
    "test_data['processed_tweet'] = test_data['cleaned_tweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c60bf5-68b9-4a73-b775-942c6d892c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any tweets became empty after preprocessing and handle them\n",
    "train_data['processed_tweet'] = train_data['processed_tweet'].apply(lambda x: x if x else \"empty_tweet\")\n",
    "test_data['processed_tweet'] = test_data['processed_tweet'].apply(lambda x: x if x else \"empty_tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4710da6b-e54d-409a-8d2e-996c281f6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis \n",
    "# Calculate tweet lengths\n",
    "train_data['tweet_length'] = train_data['tweet'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "train_data['word_count'] = train_data['processed_tweet'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22626980-697e-4236-8929-bef74a00d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tweet length distribution visualization\n"
     ]
    }
   ],
   "source": [
    "# Visualize tweet length distribution\n",
    "try:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=train_data, x='tweet_length', hue='label', bins=30, kde=True)\n",
    "    plt.title('Tweet Length Distribution by Class')\n",
    "    plt.xlabel('Tweet Length (characters)')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data=train_data, x='word_count', hue='label', bins=30, kde=True)\n",
    "    plt.title('Word Count Distribution by Class')\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tweet_length_distribution.png')\n",
    "    plt.close()\n",
    "    print(\"Saved tweet length distribution visualization\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9638e8f8-0e58-4a58-92c2-c0c28d1fd6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordcloud creation skipped: No module named 'wordcloud'\n"
     ]
    }
   ],
   "source": [
    "# Try to create word clouds if wordcloud package is available\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Function to generate wordclouds\n",
    "    def generate_wordcloud(data, label, title):\n",
    "        text = ' '.join(data[data['label'] == label]['processed_tweet'].dropna())\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=200).generate(text)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'wordcloud_class_{label}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Generate word clouds for each class\n",
    "    generate_wordcloud(train_data, 0, 'Word Cloud for Non-Hate Speech (Label 0)')\n",
    "    generate_wordcloud(train_data, 1, 'Word Cloud for Hate Speech (Label 1)')\n",
    "    print(\"Generated word clouds for both classes\")\n",
    "except Exception as e:\n",
    "    print(f\"Wordcloud creation skipped: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5764108-7500-4a27-8f78-ee095b6aea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data['processed_tweet'],\n",
    "    train_data['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_data['label']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e389e51b-d8b5-4dae-9669-f8c224650c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Feature Extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0424b57-bd22-437d-8e19-d48ff1156326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577ea619-62ea-488f-ae0d-153b81483779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to try\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    'SVM': SVC(kernel='linear', C=1.0, probability=True, class_weight='balanced', random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbc76796-c5de-4b39-8e97-88c93ecc7a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression F1 Score: 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      5945\n",
      "           1       0.48      0.77      0.59       448\n",
      "\n",
      "    accuracy                           0.93      6393\n",
      "   macro avg       0.73      0.85      0.78      6393\n",
      "weighted avg       0.95      0.93      0.93      6393\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest F1 Score: 0.6786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5945\n",
      "           1       0.80      0.59      0.68       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.88      0.79      0.83      6393\n",
      "weighted avg       0.96      0.96      0.96      6393\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM F1 Score: 0.5814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      5945\n",
      "           1       0.48      0.74      0.58       448\n",
      "\n",
      "    accuracy                           0.93      6393\n",
      "   macro avg       0.73      0.84      0.77      6393\n",
      "weighted avg       0.94      0.93      0.93      6393\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\MiniConda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:14:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 Score: 0.5719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      5945\n",
      "           1       0.85      0.43      0.57       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.90      0.71      0.77      6393\n",
      "weighted avg       0.95      0.95      0.95      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(X_val_tfidf)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    model_results[name] = f1\n",
    "    \n",
    "    print(f\"{name} F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae75d789-c855-4da3-b46c-627b174d1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model comparison visualization\n"
     ]
    }
   ],
   "source": [
    "# Visualize model comparison\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    models_df = pd.DataFrame(list(model_results.items()), columns=['Model', 'F1 Score'])\n",
    "    sns.barplot(x='F1 Score', y='Model', data=models_df.sort_values('F1 Score', ascending=False))\n",
    "    plt.title('Model Performance Comparison (F1 Score)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png')\n",
    "    plt.close()\n",
    "    print(\"Saved model comparison visualization\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model comparison plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "093bed75-f140-4ca2-bd89-6f51e40c15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "669437a6-ba5d-4518-a95b-43d17685efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced_subsample', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Best Model F1 Score: 0.6861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5945\n",
      "           1       0.72      0.66      0.69       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.85      0.82      0.83      6393\n",
      "weighted avg       0.96      0.96      0.96      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and run GridSearchCV\n",
    "try:\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Get the best parameters and model\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"\\nBest Parameters: {best_params}\")\n",
    "\n",
    "    # Evaluate the best model on validation set\n",
    "    y_val_pred_best = best_model.predict(X_val_tfidf)\n",
    "    best_f1 = f1_score(y_val, y_val_pred_best)\n",
    "    print(f\"\\nBest Model F1 Score: {best_f1:.4f}\")\n",
    "    print(classification_report(y_val, y_val_pred_best))\n",
    "except Exception as e:\n",
    "    print(f\"Grid search failed: {e}\")\n",
    "    # Use the best model from earlier comparisons if grid search fails\n",
    "    best_model_name = max(model_results.items(), key=lambda x: x[1])[0]\n",
    "    best_model = models[best_model_name]\n",
    "    best_f1 = model_results[best_model_name]\n",
    "    print(f\"Using {best_model_name} as the best model instead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e54211-ae6a-4416-854c-cc98f4555379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating ensemble model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\MiniConda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:38:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model F1 Score: 0.6924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5945\n",
      "           1       0.78      0.62      0.69       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.88      0.80      0.84      6393\n",
      "weighted avg       0.96      0.96      0.96      6393\n",
      "\n",
      "Using Ensemble for final predictions\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble model\n",
    "print(\"\\nCreating ensemble model...\")\n",
    "try:\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', models['Logistic Regression']),\n",
    "            ('rf', best_model),\n",
    "            ('svm', models['SVM']),\n",
    "            ('xgb', models['XGBoost'])\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Train the ensemble\n",
    "    ensemble.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Evaluate the ensemble\n",
    "    y_val_pred_ensemble = ensemble.predict(X_val_tfidf)\n",
    "    ensemble_f1 = f1_score(y_val, y_val_pred_ensemble)\n",
    "    print(f\"\\nEnsemble Model F1 Score: {ensemble_f1:.4f}\")\n",
    "    print(classification_report(y_val, y_val_pred_ensemble))\n",
    "\n",
    "    # Use the best model for final prediction (either ensemble or best individual model)\n",
    "    final_model = ensemble if ensemble_f1 > best_f1 else best_model\n",
    "    final_model_name = \"Ensemble\" if ensemble_f1 > best_f1 else best_model_name\n",
    "    print(f\"Using {final_model_name} for final predictions\")\n",
    "except Exception as e:\n",
    "    print(f\"Ensemble creation failed: {e}\")\n",
    "    # Use the best individual model if ensemble fails\n",
    "    final_model = best_model\n",
    "    print(\"Using best individual model for final predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773b1f67-a262-4e96-99a3-678450cd8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final predictions on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['processed_tweet'])\n",
    "test_predictions = final_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3882419-64fe-4e8e-8fc1-203058f9b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, tfidf_vectorizer, top_n=20):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance from the trained model.\n",
    "    Works with different model types (tree-based, linear, ensemble).\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained classifier model\n",
    "    - tfidf_vectorizer: Fitted TF-IDF vectorizer\n",
    "    - top_n: Number of top features to display\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with feature importance information\n",
    "    \"\"\"\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    results = {}\n",
    "    \n",
    "    # For tree-based models (Random Forest, XGBoost)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"Analyzing feature importance for tree-based model...\")\n",
    "        feature_importances = model.feature_importances_\n",
    "        \n",
    "        # Get indices of top features\n",
    "        indices = np.argsort(feature_importances)[-top_n:]\n",
    "        \n",
    "        # Create sorted lists for returning\n",
    "        top_features = [feature_names[i] for i in indices[::-1]]\n",
    "        top_importance = feature_importances[indices[::-1]]\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'model_type': 'tree_based',\n",
    "            'features': top_features,\n",
    "            'importance': top_importance\n",
    "        }\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.title(f'Top {top_n} Most Important Features')\n",
    "        plt.barh(range(top_n), feature_importances[indices], align='center')\n",
    "        plt.yticks(range(top_n), [feature_names[i] for i in indices])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.gca().invert_yaxis()  # Display highest importance at the top\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png')\n",
    "        plt.show()\n",
    "        \n",
    "    # For linear models (Logistic Regression, SVM)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"Analyzing feature coefficients for linear model...\")\n",
    "        coef = model.coef_[0]\n",
    "        \n",
    "        # Get indices of top positive and negative coefficients\n",
    "        top_positive_indices = np.argsort(coef)[-top_n:]\n",
    "        top_negative_indices = np.argsort(coef)[:top_n]\n",
    "        \n",
    "        # Create sorted lists for returning\n",
    "        pos_features = [feature_names[i] for i in top_positive_indices[::-1]]\n",
    "        pos_importance = coef[top_positive_indices[::-1]]\n",
    "        neg_features = [feature_names[i] for i in top_negative_indices]\n",
    "        neg_importance = coef[top_negative_indices]\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'model_type': 'linear',\n",
    "            'positive_features': pos_features,\n",
    "            'positive_coefficients': pos_importance,\n",
    "            'negative_features': neg_features,\n",
    "            'negative_coefficients': neg_importance\n",
    "        }\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title(f'Top {top_n} Features Associated with Hate Speech (Label 1)')\n",
    "        plt.barh(range(top_n), coef[top_positive_indices[::-1]], align='center')\n",
    "        plt.yticks(range(top_n), [feature_names[i] for i in top_positive_indices[::-1]])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title(f'Top {top_n} Features Associated with Non-Hate Speech (Label 0)')\n",
    "        plt.barh(range(top_n), coef[top_negative_indices], align='center')\n",
    "        plt.yticks(range(top_n), [feature_names[i] for i in top_negative_indices])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_coefficients.png')\n",
    "        plt.show()\n",
    "        \n",
    "    # For VotingClassifier or other ensemble models\n",
    "    elif hasattr(model, 'estimators_'):\n",
    "        print(\"Analyzing ensemble model components...\")\n",
    "        \n",
    "        # Try to find a component with feature importance\n",
    "        for name, estimator in zip(model.estimator_names_, model.estimators_):\n",
    "            if hasattr(estimator, 'feature_importances_'):\n",
    "                print(f\"Using feature importance from {name} component\")\n",
    "                feature_importances = estimator.feature_importances_\n",
    "                \n",
    "                # Get indices of top features\n",
    "                indices = np.argsort(feature_importances)[-top_n:]\n",
    "                \n",
    "                # Create sorted lists for returning\n",
    "                top_features = [feature_names[i] for i in indices[::-1]]\n",
    "                top_importance = feature_importances[indices[::-1]]\n",
    "                \n",
    "                # Store results\n",
    "                results = {\n",
    "                    'model_type': f'ensemble_{name}',\n",
    "                    'features': top_features,\n",
    "                    'importance': top_importance\n",
    "                }\n",
    "                \n",
    "                # Visualize\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.title(f'Top {top_n} Most Important Features (from {name})')\n",
    "                plt.barh(range(top_n), feature_importances[indices[::-1]], align='center')\n",
    "                plt.yticks(range(top_n), [feature_names[i] for i in indices[::-1]])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'feature_importance_{name}.png')\n",
    "                plt.show()\n",
    "                \n",
    "                break\n",
    "                \n",
    "            elif hasattr(estimator, 'coef_'):\n",
    "                print(f\"Using feature coefficients from {name} component\")\n",
    "                coef = estimator.coef_[0]\n",
    "                \n",
    "                # Get indices of top positive and negative coefficients\n",
    "                top_positive_indices = np.argsort(coef)[-top_n:]\n",
    "                top_negative_indices = np.argsort(coef)[:top_n]\n",
    "                \n",
    "                # Create sorted lists for returning\n",
    "                pos_features = [feature_names[i] for i in top_positive_indices[::-1]]\n",
    "                pos_importance = coef[top_positive_indices[::-1]]\n",
    "                neg_features = [feature_names[i] for i in top_negative_indices]\n",
    "                neg_importance = coef[top_negative_indices]\n",
    "                \n",
    "                # Store results\n",
    "                results = {\n",
    "                    'model_type': f'ensemble_{name}',\n",
    "                    'positive_features': pos_features,\n",
    "                    'positive_coefficients': pos_importance,\n",
    "                    'negative_features': neg_features,\n",
    "                    'negative_coefficients': neg_importance\n",
    "                }\n",
    "                \n",
    "                # Visualize\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                \n",
    "                plt.subplot(2, 1, 1)\n",
    "                plt.title(f'Top {top_n} Features Associated with Hate Speech (from {name})')\n",
    "                plt.barh(range(top_n), coef[top_positive_indices[::-1]], align='center')\n",
    "                plt.yticks(range(top_n), [feature_names[i] for i in top_positive_indices[::-1]])\n",
    "                plt.xlabel('Coefficient Value')\n",
    "                \n",
    "                plt.subplot(2, 1, 2)\n",
    "                plt.title(f'Top {top_n} Features Associated with Non-Hate Speech (from {name})')\n",
    "                plt.barh(range(top_n), coef[top_negative_indices], align='center')\n",
    "                plt.yticks(range(top_n), [feature_names[i] for i in top_negative_indices])\n",
    "                plt.xlabel('Coefficient Value')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'feature_coefficients_{name}.png')\n",
    "                plt.show()\n",
    "                \n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        print(\"Model doesn't provide feature importance information.\")\n",
    "        results = {'model_type': 'unknown', 'message': 'No feature importance available'}\n",
    "    \n",
    "    # Print top features\n",
    "    if 'features' in results:\n",
    "        print(\"\\nTop features for classification:\")\n",
    "        for i, (feature, importance) in enumerate(zip(results['features'], results['importance']), 1):\n",
    "            print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    elif 'positive_features' in results:\n",
    "        print(\"\\nTop features associated with hate speech (Label 1):\")\n",
    "        for i, (feature, importance) in enumerate(zip(results['positive_features'], results['positive_coefficients']), 1):\n",
    "            print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "            \n",
    "        print(\"\\nTop features associated with non-hate speech (Label 0):\")\n",
    "        for i, (feature, importance) in enumerate(zip(results['negative_features'], results['negative_coefficients']), 1):\n",
    "            print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f88f3c3c-e063-4c95-a6d5-fa0689f22972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_importance_df(model, tfidf_vectorizer):\n",
    "    \"\"\"Create a DataFrame with all features and their importance values\"\"\"\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        df = df.sort_values('importance', ascending=False)\n",
    "        \n",
    "    elif hasattr(model, 'coef_'):\n",
    "        coef = model.coef_[0]\n",
    "        df = pd.DataFrame({'feature': feature_names, 'coefficient': coef})\n",
    "        df = df.sort_values('coefficient', ascending=False)\n",
    "        \n",
    "    else:\n",
    "        # For ensemble models, try to get importance from a component\n",
    "        if hasattr(model, 'estimators_'):\n",
    "            for estimator in model.estimators_:\n",
    "                if hasattr(estimator, 'feature_importances_'):\n",
    "                    importances = estimator.feature_importances_\n",
    "                    df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "                    df = df.sort_values('importance', ascending=False)\n",
    "                    return df\n",
    "                elif hasattr(estimator, 'coef_'):\n",
    "                    coef = estimator.coef_[0]\n",
    "                    df = pd.DataFrame({'feature': feature_names, 'coefficient': coef})\n",
    "                    df = df.sort_values('coefficient', ascending=False)\n",
    "                    return df\n",
    "        \n",
    "        # If no importance info is found\n",
    "        return pd.DataFrame({'feature': feature_names, 'importance': np.zeros(len(feature_names))})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a42303fe-b7a9-4382-bf39-973033acfa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the above function\n",
    "importance_df = create_feature_importance_df(final_model, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "482b543f-8635-4496-a1ea-37cca6a34817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>allahsoil</td>\n",
       "      <td>8.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6627</th>\n",
       "      <td>white</td>\n",
       "      <td>7.134040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>racism</td>\n",
       "      <td>6.052557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>racist</td>\n",
       "      <td>5.619901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>black</td>\n",
       "      <td>5.318755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>woman</td>\n",
       "      <td>5.211439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>trump</td>\n",
       "      <td>5.159736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>bigot</td>\n",
       "      <td>4.540331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>latest</td>\n",
       "      <td>4.263644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>misogyny</td>\n",
       "      <td>4.095157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>blm</td>\n",
       "      <td>3.986716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>obama</td>\n",
       "      <td>3.922459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>equality</td>\n",
       "      <td>3.916601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>discrimination</td>\n",
       "      <td>3.809251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>jew</td>\n",
       "      <td>3.805692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>comment</td>\n",
       "      <td>3.734649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>altright</td>\n",
       "      <td>3.712822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>maga</td>\n",
       "      <td>3.591008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>systemic</td>\n",
       "      <td>3.570118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>blacklivesmatter</td>\n",
       "      <td>3.557605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>race</td>\n",
       "      <td>3.543771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>kkk</td>\n",
       "      <td>3.473121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>hate</td>\n",
       "      <td>3.436669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>paladino</td>\n",
       "      <td>3.358160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>auspol</td>\n",
       "      <td>3.326606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>christmas</td>\n",
       "      <td>3.323474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>traitor</td>\n",
       "      <td>3.320736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>term</td>\n",
       "      <td>3.316211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>misogynist</td>\n",
       "      <td>3.281697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>boycott</td>\n",
       "      <td>3.270954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  coefficient\n",
       "117          allahsoil     8.330002\n",
       "6627             white     7.134040\n",
       "4915            racism     6.052557\n",
       "4916            racist     5.619901\n",
       "606              black     5.318755\n",
       "6690             woman     5.211439\n",
       "6231             trump     5.159736\n",
       "559              bigot     4.540331\n",
       "3385            latest     4.263644\n",
       "3968          misogyny     4.095157\n",
       "636                blm     3.986716\n",
       "4305             obama     3.922459\n",
       "1831          equality     3.916601\n",
       "1566    discrimination     3.809251\n",
       "3213               jew     3.805692\n",
       "1131           comment     3.734649\n",
       "139           altright     3.712822\n",
       "3755              maga     3.591008\n",
       "5870          systemic     3.570118\n",
       "615   blacklivesmatter     3.557605\n",
       "4908              race     3.543771\n",
       "3325               kkk     3.473121\n",
       "2732              hate     3.436669\n",
       "4457          paladino     3.358160\n",
       "363             auspol     3.326606\n",
       "1018         christmas     3.323474\n",
       "6187           traitor     3.320736\n",
       "5955              term     3.316211\n",
       "3967        misogynist     3.281697\n",
       "713            boycott     3.270954"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09f7a1-499e-4440-b933-05b6d81d9c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i501",
   "language": "python",
   "name": "i501"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
